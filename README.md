# 🗣️ Speech-to-Reasoning Pipeline With Whisper & Quantized LLM

## 📌 Overview
This project demonstrates a **Speech-to-Reasoning pipeline** by combining **OpenAI’s Whisper** for speech-to-text transcription with a **Quantized Large Language Model (LLM)** for efficient reasoning and response generation.  

The pipeline enables real-time voice input, structured reasoning, and optimized inference using quantization — making it lightweight and scalable.  

---

## ✨ Features
- 🎙️ **Speech Input** → Convert audio to text with Whisper  
- 🧠 **Reasoning Engine** → Process and reason with a quantized LLM  
- ⚡ **Efficiency** → Faster inference with reduced memory usage  
- 🔗 **Modular Pipeline** → Easy to extend and integrate  

---

## 🛠️ Tech Stack
- [OpenAI Whisper](https://github.com/openai/whisper) – Speech-to-Text  
- Quantized LLM (e.g., QLoRA / GPTQ / Unsloth) – Reasoning  
- Python + Hugging Face + Transformers  

---

