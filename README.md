# ğŸ—£ï¸ Speech-to-Reasoning Pipeline With Whisper & Quantized LLM

## ğŸ“Œ Overview
This project demonstrates a **Speech-to-Reasoning pipeline** by combining **OpenAIâ€™s Whisper** for speech-to-text transcription with a **Quantized Large Language Model (LLM)** for efficient reasoning and response generation.  

The pipeline enables real-time voice input, structured reasoning, and optimized inference using quantization â€” making it lightweight and scalable.  

---

## âœ¨ Features
- ğŸ™ï¸ **Speech Input** â†’ Convert audio to text with Whisper  
- ğŸ§  **Reasoning Engine** â†’ Process and reason with a quantized LLM  
- âš¡ **Efficiency** â†’ Faster inference with reduced memory usage  
- ğŸ”— **Modular Pipeline** â†’ Easy to extend and integrate  

---

## ğŸ› ï¸ Tech Stack
- [OpenAI Whisper](https://github.com/openai/whisper) â€“ Speech-to-Text  
- Quantized LLM (e.g., QLoRA / GPTQ / Unsloth) â€“ Reasoning  
- Python + Hugging Face + Transformers  

---

